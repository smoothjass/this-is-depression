{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:09.690537200Z",
     "start_time": "2023-11-21T17:15:09.431103300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:09.690537200Z",
     "start_time": "2023-11-21T17:15:09.455109900Z"
    }
   },
   "id": "dba85ba3e22ae637"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# read data, assign column names, skip header\n",
    "data = pd.read_csv(\"depression_dataset_reddit_cleaned.csv\", names=[\"text\", \"is_depression\"], header=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:09.690537200Z",
     "start_time": "2023-11-21T17:15:09.522529200Z"
    }
   },
   "id": "50a8006442c89228"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depression:\n",
      "['i ve been sad for a couple of year now this is because of my height i am already 9 year old m but i am stuck at i feel like i am not a man because of this hence why i am extremely sad and developed body dysmorphia is this reason of mine just or am i overreacting', 'it will be two year this november since my brother died from a fentanyl overdose this completely shook up the family dynamic i moved back home to be closer to them about a year before his death while i am happy i did get to spend his last birthday with him since he is gone and the family is all split up now i hate living here i used to make double doing the type of work that i do here where i last lived my job is actually financially draining me i am a caregiver aid for disabled kid and have been for over year but ever since my brother died i find myself in very dark place then i get really angry for a second because i know he is gone and never coming back then throw in the caregiver fatigue with the grieving depression and i just feel so crazy in my head sometimes one minute i m fine the next minute i hate everyone inflation isn t helping because i am having to skip meal to make sure my kid are fed which also isn t helping my mental health i dunno how do you all cope', 'the funniest part about that tweet is the lady saying her mom wearing her sneaker will spiral her back to depression obviously doesn t have real life problem if her mom wearing her shoe sends her into depression']\n",
      "not depression:\n",
      "['i wish i had someone to talk to i m so upset no one like me anyway', 'my forehead is starting to feel like someone ha cut a slice out of it oh that s right someone cut a slice out of my forehead today', 'am insomnia is a bitch']\n"
     ]
    }
   ],
   "source": [
    "# look at some samples\n",
    "print(\"depression:\\n\" + \n",
    "      str(data[data[\"is_depression\"] == 1].sample(n=3).text.tolist()))\n",
    "print(\"not depression:\\n\" + \n",
    "      str(data[data[\"is_depression\"] == 0].sample(n=3).text.tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:09.690537200Z",
     "start_time": "2023-11-21T17:15:09.586567200Z"
    }
   },
   "id": "83a36098b2baef4c"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text             3831\n",
      "is_depression    3831\n",
      "dtype: int64\n",
      "text             3900\n",
      "is_depression    3900\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# class balance\n",
    "print(data[data[\"is_depression\"] == 1].count())\n",
    "print(data[data[\"is_depression\"] == 0].count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:09.690537200Z",
     "start_time": "2023-11-21T17:15:09.602535500Z"
    }
   },
   "id": "3462f3feda82f3d7"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depression:\n",
      "avg: 658.299138606108\n",
      "min: 3\n",
      "max: 19822\n",
      "\n",
      "not depression:\n",
      "avg: 70.97572435395458\n",
      "min: 7\n",
      "max: 144\n"
     ]
    }
   ],
   "source": [
    "# the samples suggest, the id_depression texts are longer than the others. Is that really so?\n",
    "# print average length, min length and max length of elements shows that length could be an important factor\n",
    "print(\"depression:\\n\"\n",
    "      \"avg: \" + str(sum(map(len, data[data[\"is_depression\"] == 1].text))/float(len(data[data[\"is_depression\"] == 1].text))) + \"\\n\" +\n",
    "      \"min: \" + str(min(map(len, data[data[\"is_depression\"] == 1].text))) + \"\\n\" +\n",
    "      \"max: \" + str(max(map(len, data[data[\"is_depression\"] == 1].text))) + \"\\n\"\n",
    "      )\n",
    "print(\"not depression:\\n\"\n",
    "      \"avg: \" + str(sum(map(len, data[data[\"is_depression\"] == 0].text))/float(len(data[data[\"is_depression\"] == 1].text))) + \"\\n\" +\n",
    "      \"min: \" + str(min(map(len, data[data[\"is_depression\"] == 0].text))) + \"\\n\" +\n",
    "      \"max: \" + str(max(map(len, data[data[\"is_depression\"] == 0].text))) + \"\\n\"\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:09.690537200Z",
     "start_time": "2023-11-21T17:15:09.634539800Z"
    }
   },
   "id": "28d77d0a3119a18f"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # remove extra blanks\n",
    "    re.sub(r'\\t{2,}', ' ', text)\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    # TODO other stuff\n",
    "    return text\n",
    "    \n",
    "data[\"text\"] = data[\"text\"].apply(preprocess)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:09.858574800Z",
     "start_time": "2023-11-21T17:15:09.658563400Z"
    }
   },
   "id": "d927ea90d512c026"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "# vectorizer does tokenization, data already lowercased\n",
    "# https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
    "X = data['text'].to_numpy()\n",
    "y = data['is_depression'].to_numpy()\n",
    "# Bag of words\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "X_BOW = vectorizer.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:10.710852900Z",
     "start_time": "2023-11-21T17:15:09.778572300Z"
    }
   },
   "id": "5af393e6893ceac5"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_BOW, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:10.795272500Z",
     "start_time": "2023-11-21T17:15:10.710852900Z"
    }
   },
   "id": "6aee33bffcc9b6c1"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "# train\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "# predict\n",
    "y_hat = clf.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:10.795272500Z",
     "start_time": "2023-11-21T17:15:10.740974900Z"
    }
   },
   "id": "b4e9219b69eba57e"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746 243 56 888 0.8453181583031557 0.8559036144578313\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "accuracy = accuracy_score(y_test, y_hat)\n",
    "f1 = f1_score(y_test, y_hat, zero_division=1.0)\n",
    "print(tn, fp, fn, tp, accuracy, f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:10.841684200Z",
     "start_time": "2023-11-21T17:15:10.782613Z"
    }
   },
   "id": "f26894d0096da755"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565 432 15 921 0.768753233316089 0.8047182175622541\n"
     ]
    }
   ],
   "source": [
    "# trying to encode the documents using TFIDF instead of words\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer\n",
    "# encode\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_TFIDF = vectorizer.fit_transform(X)\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_TFIDF, y)\n",
    "# train\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "# predict\n",
    "y_hat = clf.predict(X_test)\n",
    "# evaluate\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "accuracy = accuracy_score(y_test, y_hat)\n",
    "f1 = f1_score(y_test, y_hat, zero_division=1.0)\n",
    "print(tn, fp, fn, tp, accuracy, f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:11.755572800Z",
     "start_time": "2023-11-21T17:15:10.811276500Z"
    }
   },
   "id": "3cbbf0ba1ea59751"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934 0 999 0 0.4831867563372995 0.0\n",
      "(array([0], dtype=int64), array([1933], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# this is a little experiment: how well would a model perform, which is only trained on length of text?\n",
    "X = data[\"text\"].apply(len).to_numpy().reshape(-1,1)\n",
    "y = data[\"is_depression\"].to_numpy()\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# train\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "# predict\n",
    "y_hat = clf.predict(X_test)\n",
    "# evaluate\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "accuracy = accuracy_score(y_test, y_hat)\n",
    "f1 = f1_score(y_test, y_hat, zero_division=1.0)\n",
    "# it just thinks everything is not depression. so 50%. works horrible.\n",
    "# we could try adding some more features if we feel like it, but not right now.\n",
    "print(tn, fp, fn, tp, accuracy, f1)\n",
    "print(np.unique(y_hat, return_counts=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:11.812716100Z",
     "start_time": "2023-11-21T17:15:11.730887200Z"
    }
   },
   "id": "4f2699ce887a2a48"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T17:15:11.812716100Z",
     "start_time": "2023-11-21T17:15:11.771528200Z"
    }
   },
   "id": "d4f2619e718d9bf4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
